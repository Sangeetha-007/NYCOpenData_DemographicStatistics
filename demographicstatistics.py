# -*- coding: utf-8 -*-
"""DemographicStatistics.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13qqHqPxPMqy2dQng50hRR2pcIMCfCuPv
"""

import numpy as np
import pandas as pd

"""# **Introduction**

The dataset I am using is from NYC Open Data: https://data.cityofnewyork.us/City-Government/Demographic-Statistics-By-Zip-Code/kku6-nxdu. It displays the demographics based on zip code throughout NYC. The agency involved with this dataset is the Department of Youth and Community Development (DYCD). The dataset was created on July 27, 2011 and last updated on May 9, 2022. The reason I chose this dataset is because demographics is something that intrigues especially because NYC is so diverse and the demographics is always changing. I wanted to analyze this dataset to see if I get any interesting insights.
"""

data=pd.read_csv("https://raw.githubusercontent.com/Sangeetha-007/NYCOpenData_DemographicStatistics/main/Demographic_Statistics_By_Zip_Code_20231028.csv")
pd.DataFrame.head(data)
print(type(data))

"""
# **Data Exploration**"""

data.describe()

"""# **Data Wrangling**
1. Modify multiple column names.
"""

data.rename(columns={'PERCENT FEMALE': '% Female'}, inplace=True)

print(data.head())

data.rename(columns={'PERCENT MALE': '% Male'}, inplace=True)

print(data.head())

"""2. Look at the structure of your data â€“ are any variables improperly coded? Such as strings or characters? Convert to correct structure if needed. The structure of this data doesn't look like anything is improperly coded.

3. Fix missing and invalid values in data.
"""

# Check for missing values
missing_values = data.isnull()

# Count missing values in each column
missing_counts = missing_values.sum()

# Display the count of missing values in each column
print(missing_counts)

"""4. Create new columns based on existing columns or calculations. Even though there is a column called 'COUNT GENDER TOTAL', I thought I will keep the calculations simple."""

data['Total Count'] = data['COUNT FEMALE'] + data['COUNT MALE']

"""5. Drop column(s) from your dataset."""

data.drop(columns=['COUNT NRECEIVES PUBLIC ASSISTANCE', 'PERCENT NRECEIVES PUBLIC ASSISTANCE', 'COUNT PUBLIC ASSISTANCE UNKNOWN', 'PERCENT PUBLIC ASSISTANCE UNKNOWN'], inplace=True)
print(data.head())

"""6. Drop a row(s) from your dataset."""

# Step 1: Make a copy of the DataFrame
data_copy = data.copy()

#Step 2: Drop index 0 of the copy
data_copy.drop(index=0, inplace=True)

print("Updated DataFrame:")
print(data_copy.head())

print("Original dataframe:")
print(data.head())

"""7. Sort your data based on multiple variables."""

data.sort_values(by=['PERCENT CITIZEN STATUS TOTAL', 'COUNT RECEIVES PUBLIC ASSISTANCE'], ascending=[True, False], inplace=True)
print(data.head())

"""8. Filter your data based on some condition."""

# Define a condition for filtering
condition = (data['% Female'] > 0.8)

# Apply the condition to filter the data
filtered_data = data[condition]

"""9. Convert all the string values to upper or lower cases in one column.

I can't convert all the string values to upper or lower cases in one column because all the values here are integers in this dataframe, but I will now check if the 'PERCENT OTHER CITIZEN STATUS' column has numeric values or not.

10. Check whether numeric values are present in a given column of your dataframe.
"""

# Check if numeric values are present in the specified column
numeric_mask = pd.to_numeric(data['PERCENT OTHER CITIZEN STATUS'], errors='coerce').notna()

# Filter rows where numeric values are present
numeric_data = data[numeric_mask]

# Print the resulting DataFrame
print(numeric_data)

"""11. Group your dataset by one column, and get the mean, min, and max values by group."""

# Group the DataFrame by 'Group_Column' and calculate mean, min, and max
result = data.groupby('COUNT FEMALE')['% Female'].agg(['mean', 'min', 'max'])

# Print the result
print(result)

"""12. Group your dataset by two columns and then sort the aggregated results within the groups"""

# Group the DataFrame by two columns and sort within groups
result = data.groupby(['JURISDICTION NAME', '% Female'])['% Female'].agg(['mean', 'min', 'max']).reset_index()

# Sort the aggregated results within each group by 'Sort_Column'
result = result.sort_values(by=['JURISDICTION NAME', '% Female', 'mean'], ascending=[True, True, True])

# Print the result
print(result)

"""I am finding the data/row for my current zip code, 11209."""

condition2 = data['JURISDICTION NAME'] == 11209
rows_with_zip_11209 = data[condition2]
print(rows_with_zip_11209)

"""# **Conclusions**

After exploring the demographic statistics dataset, I noticed the dataset has too many 0s for better further analysis. When I pulled the row of data for the zip code 11209, I got back mostly 0s. I know for a fact how diverse Bay Ridge is, so this is incorrect. This could be due to an error of data being collected or possibly I made a mistake somewhere which I would need to check.
"""